\documentclass[acmsmall, nonacm, screen]{acmart}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}

\newif\ifdraft\drafttrue

\newcommand{\outline}[1]{
  \ifdraft
  {\color{gray}{#1}}
  \fi
}

\newcommand\doverline[1]{%
  \setbox0=\hbox{$\overline{#1}$}%
  \ht0=\dimexpr\ht0-.30ex\relax% CHANGE .15 TO AFFECT SPACING
  \overline{\copy0}%
}

\newcommand{\ifThenElse}[3]{\textsf{if}~#1~\textsf{then}~#2~\textsf{else}~#3}
\newcommand{\letIn}[3]{\textsf{let}~#1 = #2~\textsf{in}~#3}
\newcommand{\shift}[2]{\textsf{shift}~#1~\textsf{in}~#2}
\newcommand{\reset}[1]{\langle #1 \rangle}
\newcommand{\lambdaE}[2]{\lambda #1.\, #2}
\newcommand{\just}[1]{\textsf{Just}~#1}
\newcommand{\nothing}{\textsf{Nothing}}
\newcommand{\map}[3]{\textsf{map}^{\textsf{#1}}~#2~#3}
\newcommand{\unit}[2]{\textsf{unit}^{\textsf{#1}}~#2}
\newcommand{\join}[2]{\textsf{join}^{\textsf{#1}}~#2}

\lstset{ %
  backgroundcolor=\color{white},
  commentstyle=\color{ACMGreen},
  keywordstyle=\color{ACMDarkBlue},
  stringstyle=\color{ACMPurple},
  basicstyle=\ttfamily
}

\lstdefinestyle{hs}{
  language=Haskell
}

\lstdefinestyle{rkt}{
  language=lisp,
  deletekeywords={get},
  morekeywords={define},
  literate=*{(}{{\textcolor{gray}{(}}}{1}
    {)}{{\textcolor{gray}{)}}}{1}
}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\acmBooktitle{}

\begin{document}

\title{Delimited Continuations and Monads}
\subtitle{A Comparison of Programming Abstractions}
\titlenote{
  This report was compiled for part of the University of Pennsylvania's WPE-II Exam. The
  accompanying talk is available on the author's website.
}

\author{Harrison Goldstein}
\email{hgo@seas.upenn.edu}
\orcid{0000−0001−9631−1169}
\affiliation{%
  \institution{University of Pennsylvania}
  \city{Philadelphia, PA}
  \country{USA}
}

\renewcommand{\shortauthors}{Goldstein}

\begin{abstract}
  Around the year 1990, two programming abstractions were introduced: {\em delimited
  continuations} and {\em monads}. \citet{danvy1989functional} explored delimited continuations
  as a principled way of manipulating program contexts as first-class functions.
  \citet{wadler1990comprehending} popularized monads as a tool for simulating effects in a pure
  language. Though they seem to have little to do with one-another, delimited continuations and
  monads actually have a lot in common: they can solve many of the same programming problems, and
  their meta-theories are surprisingly compatible. This report re-contextualizes those early 90's
  papers and explores the commonalities between monads and delimited continuations.
\end{abstract}

\maketitle

\section{Introduction} \label{sec:introduction}
% Do I need to cast a broader net here? Something like:
% Delimited continuations and monads are classical ideas in PL literature. They are integral to the
% way we define program semantics as well as to the way we abstract code. ..asking about .
Programming languages research focuses heavily on abstractions. Abstractions enable programmers
to write code that is succinct and clear while hiding implementation details. Consider the
following programs that appear to be stateful:
\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \begin{lstlisting}[style=rkt]
  (define (program)
    (let ([i (get)])
      (put (+ i 3))
      (let ([j (get)])
        (put (* j 7))
        (get))))

  (eval-state program 3) ; 42
  \end{lstlisting}
  \label{fig:racket-state}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \begin{lstlisting}[style=hs]
  program = do
    i <- get
    put (i + 3)
    j <- get
    put (j * 7)
    get

  evalState program 3 -- 42
  \end{lstlisting}
  \label{fig:hs-state}
\end{subfigure}
\Description[State Abstraction]{Code for manipulating state.}
\label{fig:stateful-comps}
\end{figure}
\noindent Perhaps surprisingly, both of these programs are ``purely'' functional---they do not
use references or other imperative features. The illusion of state is created by underlying
abstractions that allow the programmer to think in terms of changing state without sacrificing
the advantages of purity.

The first snippet, written in Racket, uses {\em delimited continuations} to implement a stateful
API. A continuation is a first-class representation of the "rest" of a computation. For example,
when evaluating the sub-expression ``$x < 3$'' in
\[ \ifThenElse{x < 3}{10}{20}, \]
the remaining {\em context} is
\[ \ifThenElse{\_}{10}{20}, \]
and the continuation, $k$, is
\[ k = \lambdaE{b}{\ifThenElse{b}{10}{20}}. \]
The continuation captures the context as a function. In {\em A Functional Abstraction of Typed
Contexts}, \citet{danvy1989functional} present two operators for manipulating continuations: {\em
shift} (written ``$\shift{k}{e}$'') and {\em reset} (written ``$\reset{e}$''). Reset delimits the
scope of the current context---in the example above, we implicitly wrap the whole expression in a
reset. The expression ``$\shift{k}{e}$''captures the current context as a continuation, $k$, and
then executes $e$ in a fresh context. We can use shift and reset to extract the continuation from
above:
\begin{align*}
  & \reset{\ifThenElse{(\shift{k}{k~(x < 3)})}{10}{20}} \\
  \rightarrow\ & \letIn{k}{(\lambdaE{b}{\ifThenElse{b}{10}{20}})}{k~(x < 3)}
\end{align*}
Reset delimits the context, in this case the whole ``$\textsf{if}$'' expression, and shift
packages the continuation into $k$. In this example the shift body just applies $k$, so nothing
has changed---the result will be the same as the original expression. But the shift body can be
anything. In particular, if $k$ is not used at all
\[ \reset{\ifThenElse{(\shift{k}{x < 3})}{10}{20}} \]
the result is essentially an {\em exception}: the ``$\textsf{if}$'' is thrown away and the result
of the computation is just $x < 3$. Clever uses of delimited continuations like this can be used
to build up complex control flow including the state abstraction from our original example.

The second snippet simulates stateful computations using a {\em monad} in Haskell. Monads were
introduced to the programming languages literature by \citet{moggi1991notions}, but they were
popularized by \citeauthor{wadler1990comprehending} in {\em Comprehending
Monads}~\cite{wadler1990comprehending}. As a programming abstraction, monads generalize the
well-known idea of list comprehensions:
\[
  [ (x,\,y) \mid x \leftarrow [1,\, 2] ;\ y \leftarrow [3,\, 4] ]^{\textsf{List}}
\]
This expression results in the Cartesian product of lists ``$[1,\, 2]$'' and ``$[3,\, 4]$.''
Wadler observed that comprehension syntax can be to program with any monad (not just
$\textsf{List}$):
\[
  [ y \mid x \leftarrow \textsf{thisMightFail}~() ;\ y \leftarrow \textsf{thisMightFailToo}~{x} ]^{\textsf{Maybe}}
\]
This monad, usually called $\textsf{Maybe}$, implements a form of exceptions: if either of the
provided computations fail, the result of comprehension will be $\nothing$, otherwise the result
will be the value stored in $y$. There are dozens of monads that programmers use in practice,
each of which gives a different interpretation of comprehension syntax. One such monad,
$\textsf{State}$, can be used to implement our running example.

It is not immediately clear that manipulating continuations has anything to do with interpreting
comprehension syntax. One would be forgiven for assuming that these ideas are largely orthogonal.
But we have already seen that that delimited continuations and monads can be used to implement
some of the same design patterns. Could there be more overlap? Yes! It turns out that that are
many programming techniques, including state, exceptions, non-determinism, and more, that can be
implemented using either delimited continuations or monads. Furthermore, continuations actually
form a monad, and \citeauthor{wadler1990comprehending} shows that this fact can be exploited to
to recover results from \citeauthor{danvy1989functional}.

In this report I make three contributions, after a brief discussion of common notation
(\S~\ref{sec:notation}):
\begin{itemize}
  \item I summarize and re-contextualize two influential papers: {\em A Functional Abstraction of
  Typed Contexts} by \citeauthor{danvy1989functional} (\S~\ref{sec:danvy}) and {\em Comprehending
  Monads} by \citeauthor{wadler1990comprehending} (\S~\ref{sec:wadler}).\footnote{This is a
  requirement of the WPE-II exam, but I hope that reformulating these results will still be
  instructive.}
  \item I show the many design patterns that can be implemented equally well by both delimited
  continuations and monads, establishing a close relationship between the two language features
  (\S~\ref{sec:patterns}).
  \item I explore the {\em continuation monad} and show that by performing a monad-agnostic
  transformation given by \citeauthor{wadler1990comprehending} we can recover the ``extended
  continuation passing style'' transformation presented by \citeauthor{danvy1989functional}
  (\S~\ref{sec:contmonad}).
\end{itemize}
I conclude with some remarks on the broader context in which these abstractions exist
(\S~\ref{sec:conclusion}).

\section{Notes on Notation} \label{sec:notation}

\outline{
\begin{itemize}
  \item Racket and Haskell for examples
  \item Delimited Continuations: {\tt shift k in e} vs $\xi k.\,e$, {\tt reset e} vs $\langle e \rangle$
  \item Monads: join vs. bind vs. comprehensions.
    $x \leftarrow e_1 ;\!; e_2 \equiv \textsf{bind}~e_1~(\lambda x.\, e_2)$
  \item Assume a base, simply-typed lambda calculus
  \item Maybe
  \item \textsf{id}
  \item $\circ$
\end{itemize}
}

\section{{\em A Functional Abstraction of Typed Contexts}} \label{sec:danvy}

\section{{\em Comprehending Monads}} \label{sec:wadler}

Monads were originally introduced to the programming languages literature by
\citet{moggi1991notions}, but {\em Comprehending Monads} by \citet{wadler1990comprehending} made
them the popular programming abstraction that they are today. A monad is a common structure in
category theory. There, a monad is defined as a \underline{functor} with certain associated
\underline{\smash{operations}} that obey a set of \underline{laws}.

For our purposes, a functor is a type constructor (e.g. \textsf{List}, \textsf{Maybe}) with an
operation \textsf{map} that applies a function ``under'' the type constructor. For example,
\[ \map{List}{f}{\overline{x}} \]
applies $f$ to all elements of $\overline{x}$ and 
\[ \map{Maybe}{f}{\overline{x}} \]
applies $f$ to the value contained in $\overline{x}$, if one exists. (I adopt Wadler's convention
of writing monadic values---values wrapped in the monad's type constructor---with a bar over the
variable name.) Map must obey two laws:
\begin{align*}
  \textsf{map}~\textsf{id} &= \textsf{id} \\
  \textsf{map}~(g \circ f) &= \textsf{map}~g \circ \textsf{map}~f
\end{align*}

In order for a functor to be a monad, it needs two more operations: \textsf{unit} and \textsf{join}.
Applying \textsf{unit} to a value injects that value into the monad. In the case of \textsf{List},
\[ \unit{List}{x} = \textsf{singleton}~x = [x], \]
which is the simplest way to inject a value into a list. Likewise,
\[ \unit{Maybe}{x} = \textsf{Just}~x. \]

The \textsf{join} operation works on ``doubled up'' instances of the monad. It takes a doubled
value like
\begin{center}
  ``$[[1, 2], [3, 4]]$'' or ``$\textsf{Just}~(\textsf{Just}~5)$''
\end{center}
and flattens it down to a single application of the monad like
\begin{center}
  ``$[1, 2, 3, 4]$'' or ``$\textsf{Just}~5$''.
\end{center}
To be precise,
\begin{center}
  \begin{tabular}{lll}
    $\join{List}{\doverline{x}}$ & $=$ & $\textsf{flatten}~\doverline{x}$ \\
    $\join{Maybe}{\doverline{x}}$ & $=$ & $\textsf{case}~\doverline{x}~\textsf{of}~\{~\textsf{Just}~(\textsf{Just}~x) \to \textsf{Just}~x;\ \_ \to \textsf{Nothing}~\}$
  \end{tabular}
\end{center}

As mentioned, these operations must obey certain laws for the monad to behave properly:
\begin{align}
  \textsf{map}~f \circ \textsf{unit} &= \textsf{unit} \circ f \\
  \textsf{map}~f \circ \textsf{join} &= \textsf{join} \circ \textsf{map}~(\textsf{map}~f) \\
  \textsf{join} \circ \textsf{unit} &= \textsf{id} \\
  \textsf{join} \circ \textsf{map}~\textsf{unit} &= \textsf{id} \\
  \textsf{join} \circ \textsf{join} &= \textsf{join} \circ \textsf{map}~\textsf{join}
\end{align}
Intuitively, laws (1) and (2) show that \textsf{unit} and \textsf{join} are ``well-behaved'' with
respect to \textsf{map},\footnote{Wadler notes that (1) and (2) hold automatically if the
operations $\textsf{map}$, $\textsf{unit}$, and $\textsf{join}$ are implemented as {\em
polymorphic functions}, but those details are out of scope for this
report~\cite{wadler1989theorems}.} and laws (3-5) require that \textsf{unit} and \textsf{join}
are the {\em simplest} ways to do their respective tasks. For example, suppose we tried to implement
\[ \unit{List}{x} = [x,\, x,\, x,\, x,\, x]. \]
Technically this does inject a value into a list, but it is not the simplest way to do so and
\[
  (\textsf{join}^{\textsf{List}} \circ \textsf{unit}^{\textsf{List}})~[3] = [3,\, 3,\, 3,\, 3,\, 3] \neq \textsf{id}~[3]. \\
\]
Likewise, the laws require that \textsf{join} flattens a stack of monads in a simple, predictable
way.

All of this background on monads and their operations is important, but in practice using these
operations directly does not make for particularly elegant code. In the next section, I explore
Wadler's use of {\em comprehensions} to make programming with monads much more intuitive.

\subsection{Comprehensions}

List comprehensions are based on set-builder notation (e.g. $\{n + 1 \mid n \in \mathbb{N}\}$)
and were first introduced to programming by the SETL language in the
1960's~\cite{schwartz2012programming}. Since then, list comprehensions have become ubiquitous,
appearing in many modern languages including Racket, Python, and even C++ (with some abuse of
operator overloading). As shown in Section \ref{sec:introduction},
\[ [(x, y) \mid x \leftarrow \overline{x};\ y \leftarrow \overline{y}]^{\textsf{List}} \]
represents the Cartesian product of $\overline{x}$ and $\overline{y}$ in list-comprehension notation
\[ \{(x, y) \mid x \in X \wedge y \in Y\} \]
represents the Cartesian product of $X$ and $Y$ in standard mathematical notation.

Wadler starts off by adding a formal syntax for list comprehensions to our running lambda calculus:
\begin{align*}
 e &\Coloneqq ... \mid [e \mid q] \\
 q &\Coloneqq \Lambda \mid x \leftarrow e \mid (q_1;\ q_2)
\end{align*}
The symbol $q$ stands for {\em qualifiers}---qualifiers can be empty (denoted $\Lambda$), a {\em
generator} for a variable $x$, or a composition of two qualifiers. This list comprehension syntax
is defined by the following rules:
\begin{align*}
  [e \mid \Lambda] &= \textsf{singleton}~e \\
  [e_1 \mid x \leftarrow e_2] &= \textsf{map}~(\lambdaE{x}{e_1})~e_2 \\
  [e \mid (q_1;\ q_2)] &= \textsf{flatten}~[[e \mid q_2] \mid q_1] \\
\end{align*}
Wadler noticed that lists are not the only structure for which these operations make
sense---recall that \textsf{singleton} is $\textsf{unit}^{\textsf{List}}$ and \textsf{flatten} is
$\textsf{join}^{\textsf{List}}$. This means that comprehensions actually work for any monad, with
their behavior defined by:
\begin{align*}
  [e \mid \Lambda]^{\textsf{M}} &= \unit{M}{e} \\
  [e_1 \mid x \leftarrow e_2]^{\textsf{M}} &= \map{M}{(\lambdaE{x}{e_1})}{e_2} \\
  [e \mid (q_1;\ q_2)]^{\textsf{M}} &= \join{M}{[[e \mid q_2]^{\textsf{M}} \mid q_1]^{\textsf{M}}} \\
\end{align*}
Rewriting the \textsf{Maybe} example from Section \ref{sec:introduction} using these rules (and
rewriting a bit) results in
\begin{align*}
  &[ y \mid x \leftarrow \textsf{thisMightFail}~() ;\ y \leftarrow \textsf{thisMightFailToo}~{x} ]^{\textsf{Maybe}} = \\
  &\join{}{(\map{}{\textsf{thisMightFailToo}}{(\textsf{thisMightFail}~())})}
\end{align*}
which has the semantics we expect: if either computation fails the final result is \nothing\,
otherwise the result is a single \textsf{Just} wrapped around the final result.

\subsection{Examples of Monads}

\subsubsection{List and Maybe}

\subsubsection{Identity}

\subsubsection{Strictness}

\subsubsection{State}

\subsubsection{Reader}

\subsubsection{Parser}

\subsection{Translation}

\section{Common Design Patterns} \label{sec:patterns}

\section{The Continuation Monad} \label{sec:contmonad}
So far we have seen a number of examples of monads, but \citeauthor{wadler1990comprehending}
actually discusses one more: the {\em continuation monad}. Given a result type, $\rho$, the
continuation monad has operations:
\begin{center}
  \begin{tabular}{lll}
    $\textsf{type Cont}$~$\alpha$ & $=$ & $(\alpha \to \rho) \to \rho$ \\
    $\map{Cont}{f}{\overline{x}}$ & $=$ & $\lambdaE{\kappa}{\overline{x}~(\lambdaE{x}{\kappa~(f~x)})}$ \\
    $\unit{Cont}{x}$ & $=$ & $\lambdaE{\kappa}{\kappa~x}$ \\
    $\join{Cont}{\doverline{x}}$ & $=$ &
      $\lambdaE{\kappa}{\doverline{x}~(\lambdaE{\overline{x}}{\overline{x}~\kappa})}$
  \end{tabular}
\end{center}
Programs written using the continuation monad are automatically in a continuation-passing style:
sequencing
\[ [(x, y) \mid x \leftarrow \overline{x};\ y \leftarrow \overline{y}]^{\textsf{Cont}} \]
expands to
\[ \lambdaE{\kappa}{\overline{x}~(\lambdaE{x}{\overline{y}~(\lambdaE{y}{\kappa~(x,\, y)})})}, \]
which is precisely the way a tuple of expressions would be evaluated in CPS.

You might see where this is going: we can implement the delimited continuation operators, shift and
reset, as operations in the continuation monad! We can define
\begin{center}
  \begin{tabular}{lll}
    $\textsf{shift}$~$f$ & $=$ & $\lambdaE{\kappa}{f~(\lambdaE{x}{\lambdaE{\kappa'}{\kappa'~(\kappa~x)}})~(\lambdaE{x}{x})}$ \\
    $\textsf{reset}$~$\overline{x}$ & $=$ & $\lambdaE{\kappa}{\kappa~(\overline{x}~(\lambdaE{x}{x}))}$
  \end{tabular}
\end{center}
and then we can implement examples from \citeauthor{danvy1989functional} like
\[
  [x + y \mid x \leftarrow [1];\ y \leftarrow \textsf{reset}~[u + v \mid u \leftarrow [10];\ v \leftarrow \textsf{shift}(\lambdaE{k}{[b \mid a \leftarrow k~100;\ b \leftarrow k~a]})]]. \\
\]
Admittedly, this is not as terse as
\[ 1 + \reset{10 + \shift{k}{k~(k~100)}}, \]
but it says and does the same thing, and critically neither version relies on manually managing
continuation parameters.

\section{Conclusion} \label{sec:conclusion}

\begin{acks}
\end{acks}

\bibliography{references}
\bibliographystyle{plainnat}

\end{document}

% \begin{quote}
%   [In some languages,] it may be possible to jump out of an expression and then later jump back
%   into it again and resume the process of evaluation. Continuations are sufficiently powerful to
%   deal with such a situation. (This could not be taken to imply approval of jumps back into
%   expressions as a language design feature—but if a language can specify something, however odd,
%   the method used to give its formal semantics must be powerful enough to describe it.)
%   \cite{strachey2000continuations}
% \end{quote}
